{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Ia9kfOU4a9d3cC7AGTcK3LmhrJxQ8q3s",
      "authorship_tag": "ABX9TyMULlLcvDGJ/dUjqu0Bm9OW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasminjahanpuspo/Dataset_Preprocessing/blob/main/1.Dataset_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Œ Step 1: Setup Environment"
      ],
      "metadata": {
        "id": "taYt-0Q2jQ7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Mount Google Drive\n",
        "*   Access datasets stored in your Google Drive.\n"
      ],
      "metadata": {
        "id": "XpAB5dRKbqKU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQG5VOHy4zdX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ Import Required Libraries\n",
        "*   First: Load all necessary libraries for image processing, data handling, and visualization.\n",
        "*   Second: Load TensorFlow, Keras, and layers for building CNN models."
      ],
      "metadata": {
        "id": "a9KrklWlIFvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Libraries for Data Handling -------------------- #\n",
        "import numpy as np              # Numerical operations and arrays\n",
        "import pandas as pd             # Data manipulation and analysis\n",
        "import os                       # File and directory operations\n",
        "import glob as gb               # File pattern matching (e.g., get all image paths)\n",
        "\n",
        "# -------------------- Libraries for Image Processing ---------------- #\n",
        "import cv2                      # OpenCV for image reading, processing, and augmentation\n",
        "\n",
        "# -------------------- Libraries for Visualization ------------------ #\n",
        "import matplotlib.pyplot as plt # Plotting graphs and images\n",
        "import seaborn as sns           # Advanced visualizations (heatmaps, pairplots)\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "\n",
        "from PIL import Image\n",
        "import random\n",
        "import math\n",
        "\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "from scipy.ndimage import gaussian_filter"
      ],
      "metadata": {
        "id": "yl9sPyjy4_Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- TensorFlow & Keras -------------------- #\n",
        "import tensorflow as tf                       # Core TensorFlow library\n",
        "from tensorflow import keras                  # High-level API for building neural networks\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# -------------------- Dataset Utilities -------------------- #\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "# Load images from directories into TensorFlow datasets\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "# -------------------- Layers for CNN Models ---------------- #\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, LeakyReLU"
      ],
      "metadata": {
        "id": "4nGEvjWn5AqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Œ Step 2: Visualize Original Dataset\n",
        "* This step ensures the dataset is clean, balanced, and standardized.\n",
        "  "
      ],
      "metadata": {
        "id": "IUeg116OPVeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Root folder & Subfolder**  \n",
        "* Set the dataset `root folder` and detect all class `subfolders` as class names.\n"
      ],
      "metadata": {
        "id": "ZsJgNUGAKlyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder = '/content/drive/MyDrive/experimental data'  # <-- change this path\n",
        "class_names = [d for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n",
        "print('Classes found:', class_names)"
      ],
      "metadata": {
        "id": "JGQl3UIQNPMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Count**  \n",
        "* Count the number of images in each class.\n"
      ],
      "metadata": {
        "id": "ttFYYGSeKxfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count images in each class\n",
        "image_counts = {cls: len(os.listdir(os.path.join(root_folder, cls))) for cls in class_names}\n",
        "\n",
        "# Print dataset structure\n",
        "for cls in class_names:\n",
        "    print(f\"Class '{cls}' contains {image_counts[cls]} images\")"
      ],
      "metadata": {
        "id": "L9kn7j2ZQGRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Visualize Distribution**  \n",
        "Plot a bar chart to show the number of images per class and check for imbalance."
      ],
      "metadata": {
        "id": "g4UgNjiRK3HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: image_counts is a dictionary {class_name: count}\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "# Generate a list of colors automatically\n",
        "colors = plt.cm.tab20(range(len(image_counts)))  # tab20 gives 20 distinct colors\n",
        "\n",
        "plt.bar(image_counts.keys(), image_counts.values(), color=colors)\n",
        "\n",
        "plt.title('Original Dataset Distribution')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vY_iokhITQuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Rename**\n",
        "* Rename all images in each class as `classname_ID.extension`."
      ],
      "metadata": {
        "id": "G103h5B1K7g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Renaming images sequentially in each class...\")\n",
        "\n",
        "for cls in os.listdir(root_folder):\n",
        "    class_path = os.path.join(root_folder, cls)\n",
        "    if os.path.isdir(class_path):\n",
        "        images = os.listdir(class_path)\n",
        "        for idx, img_name in enumerate(images, start=1):\n",
        "            old_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            # New name: classname_1.jpg, classname_2.jpg, ...\n",
        "            new_name = f\"{cls}_{idx}.jpg\"\n",
        "            new_path = os.path.join(class_path, new_name)\n",
        "\n",
        "            os.rename(old_path, new_path)\n",
        "\n",
        "print(\"âœ… All images renamed sequentially.\")"
      ],
      "metadata": {
        "id": "Ovmdh6RWyjMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display random samples from each class with captions."
      ],
      "metadata": {
        "id": "lccsSR0fK_oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto set columns (max 3 per row for readability)\n",
        "n_classes = len(class_names)\n",
        "cols = min(3, n_classes)              # at most 3 columns\n",
        "rows = math.ceil(n_classes / cols)    # rows adjust automatically\n",
        "\n",
        "plt.figure(figsize=(5*cols, 4*rows))  # scale figure size to layout\n",
        "\n",
        "for i, cls in enumerate(class_names):\n",
        "    images = os.listdir(os.path.join(root_folder, cls))\n",
        "    sample_img = random.choice(images)\n",
        "    img_path = os.path.join(root_folder, cls, sample_img)\n",
        "    img = load_img(img_path, target_size=(128,128))\n",
        "\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(cls, fontsize=16, fontweight='bold')  # bold caption\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HLzJwLCiS_Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Resize**\n",
        "* Check all image size.\n",
        "* Resize all images to `224Ã—224` or `299*299` pixels for consistency in training.\n",
        "* Plot the original and resize image for comparison."
      ],
      "metadata": {
        "id": "izkP2tfTLGik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = root_folder  # change if needed\n",
        "\n",
        "# Collect all unique image sizes\n",
        "image_sizes = set()\n",
        "\n",
        "for class_name in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                h, w, c = img.shape\n",
        "                image_sizes.add((w, h, c))\n",
        "\n",
        "# Show results\n",
        "if len(image_sizes) == 1:\n",
        "    print(f\"âœ… All images have the same size: {list(image_sizes)[0]} (Width x Height x Channels)\")\n",
        "else:\n",
        "    print(\"âš ï¸ Found multiple image sizes in the dataset:\")\n",
        "    for size in image_sizes:\n",
        "        print(f\"   {size} (Width x Height x Channels)\")\n"
      ],
      "metadata": {
        "id": "5ppmKd_FUzol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Root folder with subfolders per class\n",
        "dataset_path = root_folder\n",
        "target_size = (224, 224)  # width, height\n",
        "\n",
        "print(\"Resizing all images to 224x224...\")\n",
        "\n",
        "for cls in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, cls)\n",
        "    if os.path.isdir(class_path):\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            # Read image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                # Resize\n",
        "                resized_img = cv2.resize(img, target_size)\n",
        "                # Overwrite the original image with resized one\n",
        "                cv2.imwrite(img_path, resized_img)\n",
        "\n",
        "print(\"âœ… All images resized to 224x224.\")\n"
      ],
      "metadata": {
        "id": "9MTxAJvY282_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select any class and one image\n",
        "classes = [d for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n",
        "selected_class = random.choice(classes)\n",
        "img_name = random.choice(os.listdir(os.path.join(root_folder, selected_class)))\n",
        "img_path = os.path.join(root_folder, selected_class, img_name)\n",
        "\n",
        "# Read original image\n",
        "original_img = cv2.imread(img_path)\n",
        "original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "original_size = original_img.shape[:2]  # height, width\n",
        "\n",
        "# Resize image\n",
        "target_size = (224, 224)\n",
        "resized_img = cv2.resize(original_img, target_size)\n",
        "resized_size = resized_img.shape[:2]  # height, width\n",
        "\n",
        "# Plot original vs resized with sizes in title\n",
        "plt.figure(figsize=(8,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original_img)\n",
        "plt.title(f'Original: {original_size[1]}x{original_size[0]}', fontsize=14, fontweight='bold')  # width x height\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(resized_img)\n",
        "plt.title(f'Resized: {resized_size[1]}x{resized_size[0]}', fontsize=14, fontweight='bold')  # width x height\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dgevLJpOk8D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Œ Step 3: Split Dataset into Train, Validation, and Test"
      ],
      "metadata": {
        "id": "eoYDvy1RQHqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Split Dataset**  \n",
        "- Divide images into Train, Validation, and Test sets (.g., `70:15:15` or `80:10:10`).  \n",
        "- Create new directories and copy images into the respective folders.\n",
        "\n"
      ],
      "metadata": {
        "id": "YkxOYGizNIVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original dataset path (with subfolders per class)\n",
        "original_dataset = root_folder  # your root folder\n",
        "\n",
        "# Path to split folder (will be created under the root folder)\n",
        "split_dataset = os.path.join(root_folder, \"split\")\n",
        "\n",
        "# Remove previous split folder if it exists\n",
        "if os.path.exists(split_dataset):\n",
        "    shutil.rmtree(split_dataset)\n",
        "\n",
        "# Create new split folder\n",
        "os.makedirs(split_dataset)\n",
        "\n",
        "# Split ratios\n",
        "train_ratio, val_ratio, test_ratio = 0.7, 0.2, 0.1\n",
        "\n",
        "print(\"ðŸ”„ Splitting dataset into train/val/test...\")\n",
        "\n",
        "# Iterate only over actual class folders (ignore any existing 'split' folder)\n",
        "for class_name in os.listdir(original_dataset):\n",
        "    class_path = os.path.join(original_dataset, class_name)\n",
        "    if not os.path.isdir(class_path) or class_name == \"split\":\n",
        "        continue  # skip non-folders and split folder itself\n",
        "\n",
        "    # List all files in the class folder\n",
        "    imgs = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "    random.shuffle(imgs)\n",
        "\n",
        "    n_total = len(imgs)\n",
        "    n_train = math.floor(train_ratio * n_total)\n",
        "    n_val   = math.floor(val_ratio * n_total)\n",
        "\n",
        "    split_imgs = {\n",
        "        \"train\": imgs[:n_train],\n",
        "        \"val\": imgs[n_train:n_train+n_val],\n",
        "        \"test\": imgs[n_train+n_val:]\n",
        "    }\n",
        "\n",
        "    # Copy images to their respective split folders\n",
        "    for split, files in split_imgs.items():\n",
        "        split_class_path = os.path.join(split_dataset, split, class_name)\n",
        "        os.makedirs(split_class_path, exist_ok=True)\n",
        "\n",
        "        for f in tqdm(files, desc=f\"{class_name}-{split}\"):\n",
        "            src_path = os.path.join(class_path, f)\n",
        "            dst_path = os.path.join(split_class_path, f)\n",
        "            shutil.copy2(src_path, dst_path)  # copy file, preserve metadata\n",
        "\n",
        "print(\"âœ… Dataset successfully split into train/val/test at:\", split_dataset)\n"
      ],
      "metadata": {
        "id": "qnJoiB-FLyTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Visualize Splits**  \n",
        "* Plot a **pie chart** showing the proportion of images in Train, Validation, and Test sets.\n"
      ],
      "metadata": {
        "id": "QRrj_iWdN0EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print counts per folder\n",
        "print(\"\\nðŸ“Š Dataset distribution after splitting:\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    total = 0\n",
        "    print(f\"\\n{split.upper()}:\")\n",
        "    split_path = os.path.join(split_dataset, split)\n",
        "    for class_name in os.listdir(split_path):\n",
        "        count = len(os.listdir(os.path.join(split_path, class_name)))\n",
        "        total += count\n",
        "        print(f\"   {class_name}: {count}\")\n",
        "    print(f\"   Total {split}: {total}\")"
      ],
      "metadata": {
        "id": "JPrs75W1Ygvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for the pie chart\n",
        "labels = ['Training (70%)', 'Validation (20%)', 'Testing (10%)']\n",
        "sizes = [70, 20, 10]\n",
        "\n",
        "#labels = ['Training (80%)', 'Validation (10%)', 'Testing (10%)']\n",
        "#sizes= [80,10,10]\n",
        "\n",
        "colors = ['teal', '#2196F3', 'coral' ]  # Green, Blue, Orange\n",
        "explode = (0.05, 0.05, 0.05)  # Slightly separate each section\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(sizes, labels=labels, colors=colors, explode=explode,\n",
        "        autopct='%1.1f%%', shadow=True, startangle=140, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
        "plt.title('Dataset Split Distribution', fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VjXyFIBgJJG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Folder Structure**  \n",
        "Visualize the directory structure of the split dataset to verify class organization.\n"
      ],
      "metadata": {
        "id": "jBK07Os8N49_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```text\n",
        "root_folder/\n",
        "â”œâ”€â”€ train/\n",
        "â”‚   â”œâ”€â”€ class_1/\n",
        "â”‚   â””â”€â”€ class_2/\n",
        "â”œâ”€â”€ validation/\n",
        "â”‚   â”œâ”€â”€ class_1/\n",
        "â”‚   â””â”€â”€ class_2/\n",
        "â””â”€â”€ test/\n",
        "    â”œâ”€â”€ class_1/\n",
        "    â””â”€â”€ class_2/\n"
      ],
      "metadata": {
        "id": "PdpzP1xuN5iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Œ Step 4: Augment Training Data\n"
      ],
      "metadata": {
        "id": "PxkRdxv0QbMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Apply Augmentations**  \n",
        "* Perform image augmentations such as rotation, shift, zoom, flip, and shear.\n",
        "* Save augmented images in a separate folder: `aug_train/`.\n",
        "*  Count the number of images per class after augmentation.\n"
      ],
      "metadata": {
        "id": "Ebngssh6aW-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to train split\n",
        "train_path = os.path.join(split_dataset, 'train')\n",
        "\n",
        "# Augmented images folder under root\n",
        "aug_root = os.path.join(original_dataset, 'aug_train')\n",
        "os.makedirs(aug_root, exist_ok=True)\n",
        "\n",
        "# Define augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Augment each class: create 3Ã— original images automatically\n",
        "for cls in os.listdir(train_path):\n",
        "    cls_path = os.path.join(train_path, cls)\n",
        "    aug_cls_path = os.path.join(aug_root, cls)\n",
        "    os.makedirs(aug_cls_path, exist_ok=True)\n",
        "\n",
        "    original_images = os.listdir(cls_path)\n",
        "    n_original = len(original_images)\n",
        "\n",
        "    # Number of augmented images per original image\n",
        "    n_aug_per_img = 3\n",
        "\n",
        "    print(f\"Augmenting class '{cls}': {n_original} originals -> {n_original * n_aug_per_img} augmented images total\")\n",
        "\n",
        "    for img_name in original_images:\n",
        "        img_path = os.path.join(cls_path, img_name)\n",
        "        img = load_img(img_path, target_size=(224,224))\n",
        "        x = img_to_array(img)\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "        i = 0\n",
        "        for batch in datagen.flow(x, batch_size=1, save_to_dir=aug_cls_path,\n",
        "                                  save_prefix='aug', save_format='jpg'):\n",
        "            i += 1\n",
        "            if i >= n_aug_per_img:  # stop after 3 augmentations per original\n",
        "                break\n"
      ],
      "metadata": {
        "id": "Wh7is2Oxk9tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Visualize Distribution**  \n",
        "* Plot a **bar chart** comparing class balance **before and after** augmentation.  "
      ],
      "metadata": {
        "id": "h5Srl3ukat5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count images in augmented train folders\n",
        "aug_counts = {cls: len(os.listdir(os.path.join(aug_root, cls))) for cls in class_names}\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "# Generate distinct colors for each bar\n",
        "colors = plt.cm.tab20(np.arange(len(aug_counts)))\n",
        "\n",
        "bars = plt.bar(aug_counts.keys(), aug_counts.values(), color=colors)\n",
        "\n",
        "plt.title('Augmented Training Data Distribution', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Number of Images', fontsize=14, fontweight='bold')\n",
        "plt.xticks(fontsize=12, fontweight='bold')\n",
        "plt.yticks(fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J5v-mEz8mac2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Œ Step 5: Comparison Section"
      ],
      "metadata": {
        "id": "EiFBGTjVHsbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Compare Counts**  \n",
        "* Compare the number of images in the original Train set versus the augmented Train set.\n",
        "* **Visualize differences** in dataset size across classes.  \n",
        "* Ensure **uniform class balance** after augmentation.\n"
      ],
      "metadata": {
        "id": "Ctmy6t2ZbgdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "train_folder = os.path.join(split_dataset, \"train\")  # original train split\n",
        "aug_folder   = os.path.join(root_folder, \"aug_train\")  # augmented train folder\n",
        "\n",
        "# Get list of classes (assumes both folders have same class names)\n",
        "classes = sorted([c for c in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, c))])\n",
        "\n",
        "# Count images per class\n",
        "train_counts = [len(os.listdir(os.path.join(train_folder, c))) for c in classes]\n",
        "aug_counts   = [len(os.listdir(os.path.join(aug_folder, c))) for c in classes]\n",
        "\n",
        "# Plot side by side bar chart\n",
        "x = np.arange(len(classes))  # the label locations\n",
        "width = 0.35  # width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "rects1 = ax.bar(x - width/2, train_counts, width, label='Train', color='skyblue')\n",
        "rects2 = ax.bar(x + width/2, aug_counts, width, label='Augmented Train', color='salmon')\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels\n",
        "ax.set_ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Classes', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Comparison: Original Train vs Augmented Train', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(classes, rotation=45)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mw2It77mRW4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“Œ Step 6: Denoise Training Data Only"
      ],
      "metadata": {
        "id": "Q3KezP4CHD47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Denoising**  \n",
        "* Apply filters like **Median or Gaussian** to reduce image noise.  "
      ],
      "metadata": {
        "id": "PD6zwyQXcHea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to augmented training images\n",
        "aug_root = os.path.join(root_folder, \"aug_train\")  # your aug_train folder\n",
        "\n",
        "print(\"ðŸ”„ Denoising augmented images...\")\n",
        "\n",
        "for cls in os.listdir(aug_root):\n",
        "    class_path = os.path.join(aug_root, cls)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    for img_name in tqdm(os.listdir(class_path), desc=f\"Denoising {cls}\"):\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            # Apply denoising\n",
        "            denoised = cv2.fastNlMeansDenoisingColored(img, None, h=10, hColor=10, templateWindowSize=7, searchWindowSize=21)\n",
        "\n",
        "            # Overwrite the original image with the denoised one\n",
        "            cv2.imwrite(img_path, denoised)\n",
        "\n",
        "print(\"âœ… All augmented images denoised successfully.\")\n"
      ],
      "metadata": {
        "id": "vQl_O6Gktndt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ðŸ”¹ **Save Images**  \n",
        "* Store denoised images in the same training data folder."
      ],
      "metadata": {
        "id": "qsb2WWSAcKJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to augmented images\n",
        "aug_root = os.path.join(root_folder, \"aug_train\")  # your augmented folder\n",
        "\n",
        "# Choose a random class and image\n",
        "cls = random.choice([c for c in os.listdir(aug_root) if os.path.isdir(os.path.join(aug_root, c))])\n",
        "class_path = os.path.join(aug_root, cls)\n",
        "img_name = random.choice(os.listdir(class_path))\n",
        "img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "# Read original image\n",
        "original_img = cv2.imread(img_path)\n",
        "original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Apply denoising (for demonstration)\n",
        "denoised_img = cv2.fastNlMeansDenoisingColored(original_img, None, h=10, hColor=10, templateWindowSize=7, searchWindowSize=21)\n",
        "\n",
        "# Plot side by side\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original_img)\n",
        "plt.title(f\"Original: {cls}/{img_name}\", fontsize=12, fontweight='bold')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(denoised_img)\n",
        "plt.title(f\"Denoised: {cls}/{img_name}\", fontsize=12, fontweight='bold')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JSEPw36gOk4r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}